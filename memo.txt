BQ容量
197MB/7w-day

推定年間使用容量
244day / 7day * 197MB = 6.7GB


# Cloud Pub/Sub
gcloud pubsub topics create minutely_task

gcloud pubsub topics create minutely15_task

gcloud pubsub topics create create_timeframe

# Cloud Storage
gsutil mb -l us-east1 -c regional gs://optionchan/

# BigQuery
bq mk --data_location=us optionchan

bq mk --time_partitioning_field=created_at --clustering_fields=last_trading_day --schema=./schema/option_price.json optionchan.option_price

bq mk --time_partitioning_field=created_at --clustering_fields=contract_month --schema=./schema/future_price.json optionchan.future_price

bq mk --time_partitioning_field=created_at --schema=./schema/spot_price.json optionchan.spot_price

# Cloud Functions
gcloud functions deploy download_jpx --runtime=python37 --region=us-east1 --trigger-topic minutely_task

gcloud functions deploy load_jpx_into_bq --runtime=python37 --region=us-east1 --trigger-resource optionchan --memory=128 --trigger-event google.storage.object.finalize

## 時間足生成
gcloud functions deploy insert_ohlc --runtime=python37 --region=us-east1 --timeout=540s --memory=128 --trigger-topic create_timeframe

## 表示用
gcloud functions deploy smile_data --runtime=python37 --region=us-east1 --trigger-http

gcloud functions deploy atm_data --runtime=python37 --region=us-east1 --trigger-http

gcloud functions deploy atm_iv_data --runtime=python37 --region=us-east1 --memory=128 --trigger-http

# Cloud Scheduler
gcloud beta scheduler jobs create pubsub minutely_task --time-zone=Asia/Tokyo --schedule="* * * * *" --topic=minutely_task --message-body=minutely_task

gcloud beta scheduler jobs create pubsub minutely_task --time-zone=Asia/Tokyo --schedule="*/15 * * * *" --topic=15minutely_task --message-body=15minutely_task

gcloud beta scheduler jobs create pubsub create_timeframe --time-zone=UTC --schedule="1 0 * * *" --topic=create_timeframe --message-body=create_timeframe

# App Engine
gcloud app deploy

# auth
共通パスワードを書き込んだ auth.txt ファイルを
appengine と functions フォルダに用意する。

# 1時間足
bq mk --time_partitioning_field=started_at --clustering_fields=last_trading_day --schema=./schema/atm_option_price.json optionchan.atm_option_price
bq mk --time_partitioning_field=started_at --clustering_fields=last_trading_day --schema=./schema/atm_target_price.json optionchan.atm_target_price
bq mk --time_partitioning_field=started_at --clustering_fields=last_trading_day --schema=./schema/atm_iv.json optionchan.atm_iv


## 初期データ投入。target_prie の部分を (atm_iv, iv), (target_price, target_price),
## (option_price, price) について行う
INSERT optionchan.atm_target_price (open, high, low, close, last_trading_day, time_frame, started_at)
WITH t1 as (
    SELECT
        (array_agg(target_price ORDER BY created_at ASC))[OFFSET(0)] open,
        MAX(target_price) high,
        MIN(target_price) low,
        (array_agg(target_price ORDER BY created_at DESC))[OFFSET(0)] close,
        last_trading_day,
        3600 time_frame,
        TIMESTAMP_SECONDS(CAST(TRUNC(UNIX_SECONDS(created_at)/3600) AS INT64) * 3600) AS started_at
    FROM optionchan.option_price
    WHERE is_atm=True AND type=2 AND created_at < '2019-05-10 00:00:00'
    GROUP BY last_trading_day, started_at
)
SELECT * FROM t1;

# bucketに3日で削除設定
gsutil lifecycle set lifecycle.json gs://optionchan/
